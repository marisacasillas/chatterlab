# chatter tools

For your re-use or adaptation, here are some of the tools we've used to speed up  data collection, annotation, and/or analysis in the Chatter Lab.

## Making daylong audio recordings

See the [ACLEW site](https://sites.google.com/view/aclewdid/home) for the latest LENA-alternative tools.

See [HomeBank's tools repository](https://github.com/homebankcode) for LENA-relevant tools.

[Ethical considerations](./lab-publications/Cychosz_et_al_2020_Longform_recordings_of_everyday_life_Ethics_for_best_practices_BRM.pdf) for daylong recordings.

[Considerations](./lab-publications/Casillas_Cristia_2019_Step-by-step_guide_to_collecting_and_analyzing_long_format_speech_environment_LFSE_recordings_Collabra.pdf) to make before conducting daylong recording resarch.

[Tutorial](https://github.com/aclew/DaylongDataTutorial-CogSci19) on getting started with daylong recordings.

## Manually annotating child language environments

[DARCLE Annotation Scheme](https://osf.io/4532e/): An adaptable template and guidelines for child language environment annotations in ELAN. Citation: [1](./lab-publications/Casillas_et_al_2017_A_new_workflow_for_semi_automitized_annotations_Interspeech.pdf)

[ACLEW Annotation Scheme](https://osf.io/b2jep/wiki/home/): A set of self-guided tutorials and gold-standard training materials, including an online test for comprehension implementing a specific version of the DARCLE Annotation Scheme for the ACLEW project. Citation: [1](./lab-publications/Casillas_et_al_2017_A_new_workflow_for_semi_automitized_annotations_Interspeech.pdf)

## Measuring turn taking in natural interaction

[chattr](https://github.com/marisacasillas/chattr-basic): A set of scripts, soon to be package, for extracting turn-taking measures from utterance-annotated data. WARNING: still under development.

## Annotating audio snippets

[Anotar](https://github.com/marisacasillas/annotate-app): Useful for text-based annotations of short audio snippets.

[IDSLabel](https://github.com/SeedlingsBabylab/idslabel): Annotate speech segments within LENA conversational blocks across 1+ sites. Citation: [1](./lab-publications/Bergelson_Casillas_et_al_2019_What_do_North_American_babies_hear_DevSci.pdf), [2](./lab-publications/Casillas_et_al_2017_What_do_babies_hear_Interspeech.pdf)

[ALICE](https://github.com/orasanen/ALICE): Automatically estimate number of words, syllables, and/or phones in speech clips. Citation: [1](./lab-publications/Rasanen_et_al_2020_ALICE_BRM.pdf)

## Annotating photos

IMCO: Efficiently annotate a directory of photos using a closed set of hotkeys.  
Version: [1](https://github.com/marisacasillas/ImCo), [2](https://github.com/kennedycasey/ImCo2)

## Creating video

[AnimatingConversation](https://github.com/marisacasillas/AnimatingConversation): Create simple animated conversation stimuli. Requires base character images, audio, and annotations of utterances.

[Weave](https://github.com/marisacasillas/Weave): Create snapshot-linked audio (i.e., video files) given an audio recording and concurrent photo stream.

## Creating non-adjacent dependency learning stimuli

Coming soon...
<!--Organize and upload NADL tools-->

----
The chatter lab is founded on the principle that diversity in everyday language use is key to the study of human language cognition. We welcome opportunities to work with scholars from all walks of life, and particularly encourage those coming from marginalized groups to reach out if interested in working with the lab.

Our lab at the University of Chicago is located on the traditional homelands of the Ojibwe, Odawa, and Potawatomi nations.