<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta name=viewport content="width=device-width,initial-scale=1"><title></title><meta name=author content="DevCows"><meta name=keywords content="devcows,hugo,go"><meta name=description content="University of Chicago"><meta name=generator content="Hugo 0.104.3"><link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel=stylesheet type=text/css><link rel=stylesheet href=//use.fontawesome.com/releases/v5.11.2/css/all.css><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link href=/css/animate.css rel=stylesheet><link href=/css/style.static/custom.css.css rel=stylesheet id=theme-stylesheet><link href=/css/custom.css?1665757096 rel=stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel="shortcut icon" href=/img/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link href=/css/owl.carousel.css rel=stylesheet><link href=/css/owl.theme.css rel=stylesheet><link rel=alternate href=https://chatterlab.uchicago.edu/index.xml type=application/rss+xml title=chatterlab><meta property="og:locale" content="en_us"><meta property="og:site_name" content="chatterlab"><meta property="og:title" content><meta property="og:type" content="website"><meta property="og:url" content="https://chatterlab.uchicago.edu/archived_courses/spring2020/course_instructions/notes/week02lecture01/"><meta property="og:description" content="University of Chicago"><meta property="og:image" content="https://chatterlab.uchicago.edu/img/sharing-default.png"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1648"><meta property="og:image:height" content="593"><meta name=twitter:card content="summary"><meta name=twitter:site content="@GoHugoIO"><meta name=twitter:title content><meta name=twitter:image content="https://chatterlab.uchicago.edu/img/sharing-default.png"><meta name=twitter:description content="University of Chicago"></head><body><div id=all><header class=navbar-affixed-top data-spy=affix data-offset-top=62><div class="navbar navbar-default yamm" role=navigation id=navbar><div class=container><div class=navbar-header><a class="navbar-brand home" href=/><img src=/img/logo.png alt=" logo" class="hidden-xs hidden-sm">
<img src=/img/logo-small.png alt=" logo" class="visible-xs visible-sm">
<span class=sr-only>- go to homepage</span></a><div class=navbar-buttons><button type=button class="navbar-toggle btn-template-main" data-toggle=collapse data-target=#navigation>
<span class=sr-only>Toggle Navigation</span>
<i class="fas fa-align-justify"></i></button></div></div><div class="navbar-collapse collapse" id=navigation><ul class="nav navbar-nav navbar-right"><li class=dropdown><a href=/>Home</a></li><li class=dropdown><a href=/news/>News</a></li><li class=dropdown><a href=/people/>People</a></li><li class=dropdown><a href=/projects/>Projects & Methods</a></li><li class=dropdown><a href=/publications/>Publications</a></li><li class=dropdown><a href=/tools/>Tools</a></li><li class=dropdown><a href=/contact/>Contact</a></li></ul></div><div class="collapse clearfix" id=search><form class=navbar-form role=search><div class=input-group><input type=text class=form-control placeholder=Search>
<span class=input-group-btn><button type=submit class="btn btn-template-main"><i class="fas fa-search"></i></button></span></div></form></div></div></div></header><div id=heading-breadcrumbs><div class=container><div class=row><div class=col-md-12><h1></h1></div></div></div></div><div id=content><div class=container><div class=row><div class=col-md-9 id=blog-post><div id=post-content><h1 id=levinson-s-c-1995-interactional-biases-in-human-thinking-in-e-n-goody-ed-social-intelligence-and-interaction-pp-221-260-cambridge-uk-cambridge-university-press>Levinson, S. C. (1995). Interactional biases in human thinking. In E. N. Goody (Ed.), Social intelligence and interaction (pp. 221-260). Cambridge, UK: Cambridge University Press.</h1><h3 id=30-march-2020>30 March 2020</h3><h3 id=the-thesis>The thesis</h3><p>As nicely laid out up front:</p><ol><li>Communication is impossible in the sense of logical signal encoding/decoding</li><li>Despite this, humans communicate effectively all the time</li><li>To do so they must use non-logical heuristics and some kinds of special reasoning</li><li>For communication to work so well so often humans also need to keep these heuristics and modes of reasoning at the front of their minds at all times</li><li>The consequence of which is that the same heuristics/reasoning affect cognition in non-communicative contexts (think, e.g., Tversky & Kahneman)</li></ol><h3 id=part-1-interactional-intelligence-coordination-and-communication>Part 1. Interactional intelligence, coordination, and communication</h3><ul><li>There is a sort of <strong>intellect for interaction</strong>: Human interactional abilities are robust to wide variation in sociocultural and neurophysiological states, and while there is some evidence for specialization as a socialized species (e.g., face recognition, very early incipient interactional skills) as well as some sub-populations for whom (neurotypical) interactional behaviors are not as readily implemented (e.g., those on the autism spectrum), interaction requires cognitive means that cross-cut any modularizable set of skills or experiences.<ul><li>Relevant question becomes <em>&ldquo;what are the underlying conceptual abilities that make social interaction possible&rdquo;</em> (p. 225)?</li></ul></li><li>Computationally, interaction feels impossible<ul><li>Adults can fairly easily coordinate with extremely little information shared between them (e.g., where to meet when, given no other prompt in Schelling-type experiments); their ability to do so relies on the salience of certain shared information and their ability to recognize and act on mutually salient information. In this sense, conceiving of interaction as a game of payoffs, in the sense of game theory, is (depending on your view) either intractable or trivial; cooperation and coordination are at the forefront of success rather than some pre-formulated benefit to the signal producer (in other words, the preferences of the participants are not independent).</li><li>Another way to think about this is that, because cooperation implicitly and at all times requires mutual consideration, and because communication is never guaranteed, it is computationally more complex to engage in effectively.</li><li>The work around this, at least from the addressee&rsquo;s perspective has focused on the &ldquo;mind reading&rdquo; part of the problem, often referred to as <strong>intention attribution</strong>. We can go down many philosophical rabbit holes here, but the key problem involves at least (1) recognizing that a signal was produced with communicative intent and (2) using the first piece of information to infer what the communicative intent was. More or less, this is just <strong>Gricean</strong> inference, to which can be added other information and heuristics. Levinson focuses on two types for the rest of section 1.<ul><li><strong>stereotyped thinking</strong> (e.g., Goody, 1978): in the broadest sense this is a reflection of what is likely given past experience with people, objects, and actions in the world (e.g., the later example of what can be expected at the service counter in the train station)<img src=figures/GoodyStereotypes.jpg alt=GoodyStereotypes></li><li><strong>sequence organization</strong> (e.g., Schegloff, 2007): the use of interactional contingency to restrict the relevance of possible prompts and answers at any given point in interaction</li></ul></li><li>Tricky computational issues that arise when we take interaction seriously include:<ol><li>Computations aren&rsquo;t done over propositions per-se but states of propositional belief in the addressee and as shared between interactants, which may themselves be &lsquo;as-if&rsquo; or may not have internatl consistency</li><li>Establishing mutual belief is infinitely regressive without some intervention/heuristic (e.g., &mldr; A believes that B believes that A believes that B believes that A believes that B believes that A intended p by saying u)</li><li>A parallel problem arises with the Gricean framework with respect to A intends that B recognize that A intends that B recognize that A &mldr;</li><li>Whereas mutually salient concepts are critical for interactional success, defining how it arises and how concepts are differentially relevantly activated is a big puzzle</li><li>Human logic isn&rsquo;t rational in any obvious sense: it can be overly specific, display one-to-many input/output relations, is computed with respect to context, and can&rsquo;t be reverse computed (see p. 230&ndash;232 for examples), which makes it feel impossible to descriptively encapsulate in a framework of rational communication</li></ol></li></ul></li><li>BUT WAIT, ISN&rsquo;T INTENTION JUST EXPRESSED VIA LINGUSTIC CODES? THAT&rsquo;S WHAT LANGUAGE IS FOR!(?) Not precisely. Three things to consider:<ul><li>Linguistic codes (i.e., lexical semantics + morphosyntax) certainly have an important role to play, but are far too ambiguous to, on their own, live up to the specificity of conveyed information. The example here is with, e.g., &ldquo;at&rdquo; in &ldquo;the man is at the door&rdquo;, &ldquo;the car is at the door&rdquo; and &ldquo;the man is at work&rdquo;&mdash;consider the differing spatial imagery and scenario-specific relevant information pulled up by those different examples.</li><li>In natural conversation, much of the language use is neither direct nor literal (see examples from 235&ndash;237), but interlocutors still manage to coordinate quickly (the balance of giving relatively little information seems sufficient most of the time, i.e., when coordination is already well underway). Consider, e.g., &ldquo;where&rsquo;d you put the thingamajig?&rdquo;&mdash;&ldquo;over there.&rdquo; Remember, this kind of language use is arguably our normal way of doing things, particularly across human society and deep into human history. A really important part of this point is that interaction is live! So the ability to get feedback in real-time may be critical to the design of this system.</li><li>Communication is not just possible but often equally fluent with non-conventional and non-linguistic signaling (see more work from Herb Clark on this point)</li></ul></li><li>So while linguistic codes can and do hugely help this process along (e.g., by pointing to intended referents, by conventional marking certain sequence initiators like wh-questions), they are not strictly necessary for successful communication and are too flexible to be depended on as a primary source of intentional meaning in many ordinary circumstances. Or as Levinson says, <em>&ldquo;we think specifically, we talk generally. I can&rsquo;t say what I mean in some absolute sense: I have to take into account what you think I will mean by it.&rdquo;</em> (p. 232).</li><li>Big picture claim: this is really where enculturation and language meet. In other words, his hypothesis is that &ldquo;culture&rdquo; as a body of concepts largely overlaps with the set of heuristics for intention attribution&mdash;the very same ones we used to relate speaker action with speaker intent during language use. in other words the &ldquo;computational miracle&rdquo; of communication breaks down to our mutual access to what is normal on average, what is likely in the current circumstances, and how one can use those sources of information to design communicative acts.</li></ul><h3 id=part-2-biases-in-human-thinking-psychological-studies>Part 2. Biases in human thinking: Psychological studies</h3><p>[Note that this part is quite interesting but less relevant to my core questions, so notes here will be a bit sparser.]</p><ul><li>This section reviews work on human decision making and (lack of) rationality, primarily focusing on the work of Tversky and Kahneman and the work on Dörner (similar basic questions, but the latter uses complex systems and compares performance within sample while the former use more simple systems and compare performance to an ideal rational thinker model).</li><li>T&K&rsquo;s work demonstrate that adults have a penchant for thinking that does not reflect the stochastic qualities of the world but would pontentially benefit interaction, including:<ul><li><strong>representativeness/teleology</strong>: the assumption that, even within small samples and in the case of truly random data, objects/actions will follow typical patterns (relevant examples from the paper/lit: categorically = likelihood of a shy person being a librarian; sequentially = getting a tails after three heads). This is quite similar to the linguistic notion of prototypicality of category members (think Eleanor Rosch), but applied at a cognitively more general scope.</li><li><strong>availability</strong>: more or less the assumption that salient things are more normal/typical (relevant example: the impression that there are more words starting with &lsquo;r&rsquo; than words with &lsquo;r&rsquo; as the third letter). The link to interaction here is mutual salience as a heuristic for pointing to likely speaker meanings.</li><li><strong>determinism/overconfidence/presumption of causality</strong>: this tendency leads people to make unlicensed causal inferences (i.e., to generally look for meaning, even when meaning is not part of any possible &ldquo;design&rdquo; in the signal) and isn&rsquo;t expanded upon much; the link to interactive behavior, I presume is through the deterministic-feeling reconstruction of intentions during interactional sequences. Some of this may also relate to the idea of <em>&ldquo;single-solution&rdquo;</em> thinking&mdash;determine what the meaning is and act on it. In interaction this pays off because we are usually right and, when wrong, we can be alerted to this soon after.</li><li>There are also some points made about sequentiality, but I find these a little less convincing because they are different types of sequential processing from the shared sequential structure at issue in conversation (e.g., coin tosses, causes-outcomes).</li><li>The question raised by Levinson is whether these failings are justified by the help they provide for language comprehension. in other words, perhaps these adaptations are to facilitate human interaction, and just bleed into our other ways of thinking about the world.</li></ul></li><li>This is followed up by a review of Dörner&rsquo;s work on similar problem solving, but with complex systems where there is no single rational response given the many factors at play (actually I&rsquo;m not sure that&rsquo;s true, but certainly I can imagine that it&rsquo;s beyond practical computational reach, esp in 1995), in which adults showed many of the same failings, but in different forms. Of these the particular one focused on was a kind of stickiness to the initial solution, linking again to this idea of a quick overconfidence/determinism that is useful in interaction as well as a more tenuous link to the idea of losing face over a wrong solution. Also makes some links to a focus on one-at-a-time topic processing, but this is really quite far from something that obviously and specifically benefits interaction!</li><li>For both research paradigms (but more so for T&K), Levinson makes the case that interactive biases may be built into the tasks by the participants&rsquo; meta-cognition about task relevance and the (real or imagined) experimenter&rsquo;s role as a recipient of their responses.</li></ul><h2 id=critical-and-clarificatory-questions-and-ideas>Critical and clarificatory questions and ideas</h2><ul><li>Levinson mentions the idea that, in coordination games, <em>&ldquo;Both win if and only if each does what the other expects each to do; otherwise both lose [&mldr;] it doesn&rsquo;t matter much which action is taken as long as it matches the other&rsquo;s expectation&rdquo;</em> (p. 226&ndash;227) &#187; To me this seems more like the characterization of a pure opposite to antagonistic interaction rather than a characterization of typical human interaction, which may be more of a meld of cooperation and coercion; maybe the more appropriate view of conversation is one of mutual manipulation, which is not quite the same since I often have a very definite short-term goal for the interaction (e.g., getting this toddler to put her shoes on; making a decision about what to cook for lunch for a group).</li><li>Part 1 ends with the claim that we (as addressees/interactional parsers) settle on an intended meaning with the experience of definiteness&mdash;definiteness that is revisable depending on what happens next in interaction. But how often is this certainty really achieved and, actually, why does it matter for the overall functioning of the model?</li></ul><h2 id=relation-to-my-current-projects>Relation to my current projects</h2><ul><li>Very little in here about children, but of course the basic question of how kids come into this system is one tackled by many people&rsquo;s work and not just my own. Interestingly there may be a divide between how children build up stochastic ideas about what is &ldquo;normal&rdquo; and truly normative/socialized ones that influence their in-the-moment actions during interaction.</li><li>Relating to my Nepperlands study and future follow-up work in particular:<ul><li>What assumptions do children bring to interactional settings?</li><li>How do they use (conventionalized) cues to sequence organization to bring themselves into linguistic and conceptual coordination?</li></ul></li></ul><h2 id=associated-phenomena-to-consider-covering-in-class>Associated phenomena to consider covering in class</h2><ul><li>Schelling games</li><li>Shannon model of communication</li><li>Game theory</li><li>Implicature</li></ul><h2 id=further-reading>Further reading</h2><h3 id=probably-should-have-a-look-at>Probably should have a look at</h3><ul><li>Esther Goody&rsquo;s work on stereotypes (cited here as &ldquo;1978a&rdquo; but there&rsquo;s no refs-cited section!) and on <strong>Anticipatory Interactive Planning (AIP)</strong>.</li></ul><h3 id=for-funsies>For funsies</h3><ul><li>Frames of Mind (1986) by Howard Gardner. Reportedly on diversity of intelligence types, though probably very out of date by now!</li></ul><h2 id=overall-impressions>Overall impressions</h2><p>A wonderfully written wide-ranging piece that cuts to the heart of issues that still plague how human language is studied. Blergh endnotes&mdash;I only skimmed them, and only after reading the rest of the chapter. But ANYHOW, I found the this text both fun to read and thought provoking. Still very relevant despite the fact that it&rsquo;s been 25 years since it was published!</p><hr><h1 id=clark-h-h-1996-joint-actions-in-using-language-pp-5991-cambridge-uk-cambridge-university-press>Clark, H. H. (1996). Joint Actions. In Using Language (pp. 59–91). Cambridge, UK: Cambridge University Press.</h1><h3 id=31-march-2020>31 March 2020</h3><ul><li>Note: Activities/actions/acts: the first two are done within some temporal space (i.e., they are enacted and dealt with as they unfold) and the last is done in a single moment and, more or less, without respect to a temporal space&mdash;at least that&rsquo;s what the term use here seems to imply!</li><li><strong>Joint actions</strong> are coordinated actions by 2+ prople, including what they (intend to) do (&ldquo;content&rdquo;) and the resources they recruit to do so (&ldquo;process&rdquo;).</li><li>Joint action and language use are not equivalent because joint action is often done without recourse to linguistic resources and can even be conceived of within hierarchically related simultaneous actions.<ul><li>Instead, we can think of most language use as a type of joint action that utilizes a system of shared linguistic conventions that are useful for doing things jointly.</li></ul></li><li>Terminological hierarchy goes as follows:<ul><li>Intentional actions<ul><li>Indivividual actions: only completable by individual people<ul><li>Autonomous (i.e., no intended coordination with others)</li><li>Participatory (i.e., intended coordination with others)</li></ul></li><li>Joint actions: only completable by ensembles of people, and performed by means of individual actions</li></ul></li></ul></li><li>Side note: apparently coordinated behavior can also emerge as a consequence of <strong>adaptive</strong> or <strong>deceptive</strong> actions (e.g., a spy following their target or a player faking out their opponent, respectively), but we don&rsquo;t focus on these ways of realizing coordinated behavior right now</li><li><strong>Schelling coordination problems</strong> (e.g., Schelling, 1960) in these puzzles, participants reason backwards from a joint goal to a joint action. The tasks are characteristically explicit/meta-cognitive, discrete, and single-shot in nature, and the solution is defined by the inter-dependence of participants&rsquo; thinking. Some classic examples include trying to come up with the same answer across participants for:<ul><li>Heads or tails?</li><li>Pick a number between X and Y.</li><li>Where would you go when to meet someone in location Z?</li><li>Sensible answers to these prompts rely on people&rsquo;s ability to identify shared expectations. On its face, this task is about predicting what the other person will do, but prediction is underlain by the ability to recognize mutually salient signals which can serve as a <strong>key</strong> or <strong>coordination device</strong> to point to an answer.<ul><li><strong>Coordination devices</strong><ul><li>Are things that are (broadly construed) salient and functionally informative in present circumstances, which can mean concepts that are highlighted by explicit agreement, precedent, convention, perceptual/conceptual prominence/perspicuousness, etc..</li><li>The best coordination device is determined by the solution most salient with respect to common ground (<em>&ldquo;principle of joint salience&rdquo;</em>), such that the person and interactional context can hugely shape what the right (or at least sufficient) &ldquo;key&rdquo; is (e.g., the example Schelling tasks above with a randomly chosen adult from anywhere in the world vs. in Chicago; the number-choosing prompt after just having watched the film 28 Days Later, etc.).</li></ul></li></ul></li></ul></li><li>Coordination implies audience design, at some level &#187; participant joint action implies that interactional contributions will be formulated such that participants can jointly solve them, which Clark frames within two content premises and one process premise:<ul><li><em>Solvability premise:</em> when a participant sets forth a coordination problem, co-participants can proceed with trying to find a solution knowing that the problem was chosen and posed ~for them~ with the belief that there is a solution that the participants can converge upon.</li><li><em>Sufficiency premise:</em> Problem prompts in the above ^^ sense include an assumption that all necessary information (taking common ground as also given) for finding a solution is included in the prompt.</li><li><em>Immediacy premise:</em> If participants are working within a sequence of time-constrained problems, they should go for immediate solutions (i.e., which are by-design sought after in this context).</li></ul></li><li><strong>Convention</strong>: <em>&ldquo;a community&rsquo;s solution to a recurrent coordination problem&rdquo;</em> (reformulated from Lewis, 1969; p. 70) defined here as:<ol><li>a regularity <code>r</code> in behavior that is</li><li>(partly) arbitrary</li><li>common ground in a given community, being</li><li>used/usable as a <strong>coordination device</strong> that is</li><li>specifically designed to address a recurrent coordination problem of <code>s</code>.</li></ol></li><li>Conventions include (all of) lexical and grammatical components of a language, but also things like greeting routines, expectations about personal space and public behavior, traffic systems, etc.</li><li><strong>Signaling systems</strong> rely on conventional or otherwise agreed-upon meanings to coordinate behavior and can be truly symbolic (e.g., human language/Python 3/traffic signs) or more on the ad-hoc side (e.g., placing a lost glove where it will garner the attention of its owner), or somewhere between (e.g., the sexton hanging lamps in the Paul Revere story, sending a bill to &ldquo;the ham sandwich at table 9&rdquo;)<ul><li>Signaling systems are HUGELY important for quickly coordinating complex behaviors, but are dependent on the more general interactional processes for coordinating (discussed here) and intention attribution (discussed here and in the Levinson reading this week). We need these skills for, e.g.,:</li><li>Dealing with errors and true ambiguities<ul><li>Dr. Casillas (don&rsquo;t ask for medical advice!)</li><li>&ldquo;criminal lawyer&rdquo;</li><li>&ldquo;she&rsquo;s more Levinsonian than Schegloffian&rdquo;</li><li>&ldquo;pulling a Clark&rdquo;</li><li>&ldquo;his Uncle Tony&rdquo;</li></ul></li><li>Efficiently conveying complex, multi-layered messages<ul><li>Indexical signals to identity, community, specific personae, etc.: &ldquo;pop&rdquo;, &ldquo;noice&rdquo;, &ldquo;Jiminy Cricket!&rdquo;</li><li>Referential layering: &ldquo;Khaaan!&rdquo;</li></ul></li><li>NOTE: This ability to not just deal with but play with ambiguity in language is one of the things that intuitively feels very special about it but is hard to formally capture and is also made possible by the fundamental interactional skills we discuss in this class. In Levinson&rsquo;s terms, this goes back to the idea of &ldquo;thinking specifically but speaking generally&rdquo;.</li></ul></li><li><strong>Continuous coordination</strong>: most coordination problems are continuous, meaning that the solutions bear out over some defined time scale and are formed by adaptive decisions that are made in the moment by participants.<ul><li>Can be <strong>periodic/regular</strong> or <strong>aperiodic</strong> in when contributios are made</li><li>Can be <strong>balanced</strong> or <strong>unbalanced</strong> in who is leading the effort</li><li>Conversation is aperiodic and unbalanced (i.e., people talk one at a time for non-prescribed periods of time)</li></ul></li><li>Complex joint actions are typically made up of phases and subphases, which each have entry and exit times that ~themselves~ must be coordinated between participants in addition to the coordination of action content.<ul><li>Note: for sequentially dependent acts, as in the handshake, the end of one phase is sometimes the signal to the start of th next one. <img src=figures/JAPhases.jpg alt=JAPhases></li><li>Synchrony among these entry and exit times, together with the intended content for each subphase is the foundation for complex coordination (<em>the principle of synchrony</em>), and we as participants understand that more effort may mean more delay in designing and responding to interactional moves (<em>the principle of processing time</em>)<ul><li>One implication of this is that information must be packaged such that entry and exit times are adequately marked, along with cues to alignable content; otherwise break down occurs or other strategies come into play. A great example from a conversational clip is shown on page 88.</li></ul></li></ul></li><li><strong>Asynchronous joint actions</strong> (that&rsquo;s us!! that&rsquo;s this!!) are characterized by a lack of synchrony at immediate time scales, but do not mean that the interaction is any less &ldquo;joint&rdquo;; rather the implication is just that audience design must be considered at a more comprehensive scale in order to achieve comparable communicative/coordination success<ul><li>In other words, we&rsquo;re almost working our way back toward Schelling and his one-shot games :)</li></ul></li></ul><h2 id=critical-and-clarificatory-questions-and-ideas-1>Critical and clarificatory questions and ideas</h2><ul><li>Some of these principles seems straightforwardly Gricean (e.g., saliency, solvability, sufficiency) and some derivable from cognitive constraints (e.g., immediacy from (working) memory) &#187; how should we think about these tenets? What aspects might be specially adapted for interaction?</li><li>How do these notions of salience relate to those raised by the Levinson (1995) paper? We here rely more on the idea of common ground, but how categorical is that relation? Is it just a special case of more gradient and multi-dimentional mutual saliency? How would we get evidence that it is phenomenologically distinct?</li><li>What are the developmental implications of coordination devices, particularly those that are conventionalized? Are there some &ldquo;universally available&rdquo; ones to (NT) humans?</li><li>The idea of action hierarchies makes a lot of sense, but how are these supposed to be abstractly constructed, represented, updated, remembered, and detailed? What is required?</li><li>How do people know when it&rsquo;s possible to use specific &ldquo;codes&rdquo; in their utterance design such that meaning is only accessible to some? Do they have to mark this via other means? If not, is the recovery process identical to this general one for resolving ambiguity and breakdown in interaction?</li></ul><h2 id=relation-to-my-current-projects-1>Relation to my current projects</h2><ul><li>As was the Levinson (1995) paper this week, this Clark chapter relates closely to my Nepperlands study and the development of language as a cue to interactional coordination (i.e., projecting that an answer is coming to a question)</li><li>I was also reminded of the &ldquo;jelly bean factory experiment&rdquo; by the entry and exit coordination. This is a problem we&rsquo;ll deal with in more detail later on, but basically the idea of precise signals for ~exit~ points in particular is really difficult in practice, even with conventionalized symbols. This deserves more thought.</li></ul><h2 id=associated-phenomena-to-consider-covering-in-class-1>Associated phenomena to consider covering in class</h2><ul><li>Signal system evolution (in the lab and in the wild)</li><li>Fillers and delay markers</li><li>Conversational overlap and gap</li></ul><h2 id=further-reading-1>Further reading</h2><h3 id=probably-should-have-a-look-at-1>Probably should have a look at</h3><ul><li>The chapter on common ground from this book&mdash;useful to review</li></ul><h3 id=for-funsies-1>For funsies</h3><ul><li>Lewis&rsquo;s (1969) original work on language as a coordination problem</li></ul><h2 id=overall-impressions-1>Overall impressions</h2><p>Clear and engaging as always. This chapter provides lots of more concrete feeling conceptual &ldquo;tools&rdquo; for thinking about coordination, though some of these convenient shortcuts may have pretty heavy and more theoretically tricky embeddings when analyzed on, e.g., the psycholinguistic/cognitive processing level or at the larger scope of coordination and salience in humans and non-human animals. It&rsquo;ll be interesting to hear students&rsquo; reactions!</p><hr></div></div><div class=col-md-3></div></div></div></div><footer id=footer><div class=container><div class="col-md-4 col-sm-6"><h4>About us</h4><p>The chatter lab is founded on the principle that diversity in everyday language use is key to the study of human language cognition. We welcome opportunities to work with scholars from all walks of life, and particularly encourage those coming from marginalized groups to reach out if interested in working with the lab.<br><br>Our lab at the University of Chicago is located on the traditional homelands of the Ojibwe, Odawa, and Potawatomi nations.</p><hr class="hidden-md hidden-lg hidden-sm"></div><div class="col-md-4 col-sm-6"></div><div class="col-md-4 col-sm-6"><h4>Contact</h4><p class=text-uppercase><strong>Green Hall Room 011</strong><br>5848 S University Avenue<br>Chicago, IL 60637</p><a href=/contact/ class="btn btn-small btn-template-main">Go to contact page</a><hr class="hidden-md hidden-lg hidden-sm"></div></div></footer><div id=copyright><div class=container><div class=col-md-12><p class=pull-left>Copyright (c) 2022. Marisa Casillas. chatter lab.</p><p class=pull-right>Template by <a href=https://bootstrapious.com/p/universal-business-e-commerce-template>Bootstrapious</a>.
Ported to Hugo by <a href=https://github.com/devcows/hugo-universal-theme>DevCows</a>.</p></div></div></div></div><script src=//code.jquery.com/jquery-3.1.1.min.js integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin=anonymous></script>
<script src=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js></script>
<script src=/js/front.js></script>
<script src=/js/owl.carousel.min.js></script></body></html>