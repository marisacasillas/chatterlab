<!DOCTYPE html>
<html lang="en-us">

  <head>
    <meta charset="utf-8">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title></title>
<meta name="author" content="DevCows" />




<meta name="keywords" content="devcows, hugo, go">


<meta name="description" content="Site template made by devcows using hugo">

<meta name="generator" content="Hugo 0.94.2" />


<link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>


<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.11.2/css/all.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link href="/chatterlab/css/animate.css" rel="stylesheet">



  <link href="/chatterlab/css/style.static/custom.css.css" rel="stylesheet" id="theme-stylesheet">



<link href="/chatterlab/css/custom.css" rel="stylesheet">



  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->



<link rel="shortcut icon" href="/chatterlab/img/favicon.ico" type="image/x-icon" />
<link rel="apple-touch-icon" href="/chatterlab/img/apple-touch-icon.png" />


<link href="/chatterlab/css/owl.carousel.css" rel="stylesheet">
<link href="/chatterlab/css/owl.theme.css" rel="stylesheet">


<link rel="alternate" href="https://marisacasillas.github.io/index.xml" type="application/rss+xml" title="chatterlab">








<meta property="og:locale" content="en_us">
<meta property="og:site_name" content="chatterlab">
<meta property="og:title" content="">
<meta property="og:type" content="website">
<meta property="og:url" content="https://marisacasillas.github.io/chatterlab/projects/" />
<meta property="og:description" content="Site template made by devcows using hugo">
<meta property="og:image" content="https://marisacasillas.github.io/chatterlab/img/sharing-default.png">
<meta property="og:image:type" content="image/png">



  <meta property="og:image:width" content="800">
  <meta property="og:image:height" content="420">






<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@GoHugoIO">
<meta name="twitter:title" content="">

<meta name="twitter:image" content="https://marisacasillas.github.io/chatterlab/img/sharing-default.png">

<meta name="twitter:description" content="Site template made by devcows using hugo">


    
  </head>

  <body>

    <div id="all">

        <header class="navbar-affixed-top" data-spy="affix" data-offset-top="62">
    <div class="navbar navbar-default yamm" role="navigation" id="navbar">
        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="/chatterlab/">
                    
                      <img src="/chatterlab/img/logo.png" alt=" logo" class="hidden-xs hidden-sm" />
                      <img src="/chatterlab/img/logo-small.png" alt=" logo" class="visible-xs visible-sm" />
                    
                    <span class="sr-only"> - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fas fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  

                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/">Home</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/news/">News</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/people/">People</a>
                  </li>
                  
                  
                  
                  

                  
                    
                  

                  

                  
                    
                      
                    
                      
                    
                      
                    
                      
                    
                  

                  
                  <li class="dropdown active">
                    <a href="/chatterlab/projects/">Projects &amp; Methods</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/publications/">Publications</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/tools/">Tools</a>
                  </li>
                  
                  
                  
                  

                  

                  

                  

                  
                  <li class="dropdown ">
                    <a href="/chatterlab/contact/">Contact</a>
                  </li>
                  
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">
                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fas fa-search"></i></button>
                </span>
                    </div>
                </form>
            </div>
            
        </div>
    </div>
</header>




        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1></h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            

            <div class="container">

                <div class="row">

                    <div class="col-md-12">

                        <div>
                          <h1 id="chatter-lab-projects-and-methods">chatter lab projects and methods</h1>
<p>As an interdisciplinary lab, we work on a rather diverse array of topics using an even broader set of methodological approaches. We give a short introduction here to three of these research topics, giving some examples of methods for each:</p>
<p><a href="https://marisacasillas.github.io/chatterlab/projects.html#language-development-across-cultural-contexts">Language development across cultural contexts</a></p>
<p><a href="https://marisacasillas.github.io/chatterlab/projects.html#real-time-language-use-in-interaction">Real-time language use in interaction</a></p>
<p><a href="https://marisacasillas.github.io/chatterlab/projects.html#multimodal-conversational-coordination">Multimodal conversational coordination</a></p>
<hr>
<h3 id="language-development-across-cultural-contexts">Language development across cultural contexts</h3>
<p><em>We conduct quantitative investigations into the early language environments and language development of children growing up in a variety of cultural and linguistic contexts. Much of this work takes a comparative perspective on a topic that is relevant to two or more populations. However some of the work we do focuses on special topics unique to a particular community.</em></p>
<p>One method we use in this work is <strong>daylong audio recordings</strong>: that is, young children wear audio-photo recording vests while they spend a full day at home; we then transcribe and annotate parts of the resulting 9–11-hour recordings to measure aspects of their interactional environment. Together with <a href="https://www.mpi.nl/people/brown-penelope">Penny Brown</a> and <a href="https://www.mpi.nl/people/levinson-stephen">Steve Levinson</a>, we recently used this approach to study how much speech children under age three are exposed to (and from whom) in two unrelated rural Indigenous communities (the Tseltal Maya of Chiapas, Mexico and the Yélî people of Rossel Island, Milne Bay, Papua New Guinea), finding that young children were rarely directly addressed, but were exposed to quite a lot of speech directed to others. They also heard more speech from other children than children in urban, Western households typically do. Despite some differences between the two populations, these children reach early linguistic milestones at similar rates to each other and to previously studied Western children (read more <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_et_al_2020_Early_language_experience_in_a_Tseltal_Mayan_village_ChiDev.pdf">here</a> and <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_et_al_2021_Early_language_experience_in_a_Papuan_community_JCL.pdf">here</a>).</p>
<p>Another method we use for this work is <strong>gaze-based experiments</strong>, such as looking-while-listening, central fixation habituation, and observer gaze. In these experiments, the child and one of their caregivers step into an experiment tent and sit on a small stool in front of a laptop. We then begin playing visual stimuli, usually audio-visual video stimuli, on the laptop and continuously record children&rsquo;s head and eye movements with a video camera mounted above the laptop, an eyetracker, or both. This method can be used with infants, children, and adults alike. We make sure to use the same experiment tent everywhere we test, even when testing in Chicago! Initial results to be posted here soon.</p>
<p>We also use a variety of other experimental tasks that require an overt response from the participant, either by asking for them to respond linguistically or by asking them to point or press a button on a tablet. For example, together with <a href="https://sites.google.com/site/acrsta/">Alex Cristia</a> we are investigating how children on Rossel Island learn the language&rsquo;s elaborate sound system by asking them to listen to and repeat novel words (<strong>non-word repetition</strong>). Another example is in our investigation of how these children learn about kinship terms like &lsquo;uncle&rsquo; and &lsquo;grandmother&rsquo;, which we are conducting with <a href="https://www.mpi.nl/people/levinson-stephen">Steve Levinson</a>. In this study we ask children to name their ancestral kin on their mother&rsquo;s and father&rsquo;s sides of the family and also to define each kin type so that we can understand how their linguistic and conceptual knowledge of kinship develops. In both of these examples, we are finding that children are still developing some mastery of sounds and words of their language well into their early teens. Intial results to be posted here soon.</p>
<h3 id="real-time-language-use-in-interaction">Real-time language use in interaction</h3>
<p><em>We use a variety of quantitative psycholinguistic methods to explore how interactional demands influence in-the-moment language production and language understanding during conversation.</em></p>
<p>One method we use in this work is <strong>observer gaze</strong>, which is a gaze-based experimental task in which the participant watches a video of a two-person conversation between two people, puppets, or drawn characters. We track participants&rsquo; eye movements while they watch the videos, either using an automated computer system or by manually annotating a video of their eye movements. We then estimate when and how often participants look anticipatorily at the person who will take the next turn. We are interested in finding out how these spontaneous predictions by participants are driven by the linguistic cues present in the unfolding speech. For example, by running observer gaze experiments with adults and children in the US, the UK, and the Netherlands we have discovered that, when participants ages two and above hear a question, they are much more likely to look at the addressee in anticipation of the answer. Together with <a href="https://sites.google.com/site/immelammertink/home">Imme Lammertink</a>, Maartje de Vries, and <a href="https://www.mpi.nl/people/rowland-caroline">Caroline Rowland</a>, we are now conducting a very large study of Dutch speakers in the Netherlands to find out whether participants need to understand the whole question to make their prediction, or if they are just scanning the speech signal for &lsquo;key&rsquo; words like &ldquo;where&rdquo; and &ldquo;who&rdquo; and &ldquo;you&rdquo; (read more <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_Frank_2016_The_development_of_childrens_ability_to_track_and_predict_turn_structure_in_conversation_JML.pdf">here</a> and <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Lammertink_et_al_2015_Dutch_and_English_toddlers_use_of_linguistic_cues_to_predicting_upcoming_turn_boundaries_Frontiers.pdf">here</a>).</p>
<p>Another method we use is <strong>quantitative corpus study</strong>. For example, we have carefully annotated the timing of turn transitions during parent-child conversation in English; to do this we count measure the number of milliseconds that pass between the end of a parent&rsquo;s question and the start of a child&rsquo;s answer. When we conducted a study like this on children learning American English together with <a href="https://www.gordon.edu/susanbobb">Susan Bobb</a> and <a href="https://web.stanford.edu/~eclark/">Eve Clark</a>, we found that even very young children were capable of producing some fast responses, but only if what they wanted to say was easy to plan (e.g., &ldquo;yes!&rdquo;). If they wanted to answer with something more complicated (e.g., &ldquo;no, that one!&rdquo;) they took longer to respond. These results suggest that the real &ldquo;cost&rdquo; when children are slow to respond is in how they plan their answers and <em>not</em> in their ability to rapidly recognize what is being asked of them (read more <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_et_al_2016_Turn_taking_timing_and_planning_in_early_language_acquisition_JCL.pdf">here</a> and <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_2014_Taking_the_floor_on_time_ClarkTiLARVolume.pdf">here</a>).</p>
<p>We have used a range of other experimental methods to investigate online language processing for conversation. For example, with <a href="https://research.tilburguniversity.edu/en/persons/connie-de-vos">Connie de Vos</a> and colleagues, we developed a novel button-press measure of turn-end prediction for Sign Language of the Netherlands (NGT) to test where signed utterances are perceived to end and to understand whether predictions were affected by whether the turn was a question or not (read more <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Casillas_et_al_2015_The_perception_of_stroke-to-stroke_turn_boundaries_in_signed_conversation_CogSci.pdf">here</a>). With <a href="https://research.tilburguniversity.edu/en/persons/sara-b%C3%B6gels">Sara Bögels</a> and colleagues we have used a neural imaging method called electroencephalography (EEG) with Dutch speakers to investigate when during a question addressees begin to plan their response and to understand how their speech planning affects their ability to simultaneously listen (read more <a href="https://marisacasillas.github.io/chatterlab/lab-publications/Bogels_et_al_2018_Planning_versus_comprehension_in_turn_taking_Neuropsychologia.pdf">here</a>).</p>
<h3 id="multimodal-conversational-coordination">Multimodal conversational coordination</h3>
<p>More information to come here!</p>

                        </div>

                    </div>

                </div>
                

            </div>
            

            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            <p>The chatter lab is founded on the principle that diversity in everyday language use is key to the study of human language cognition. We welcome opportunities to work with scholars from all walks of life, and particularly encourage those coming from marginalized groups to reach out if interested in working with the lab.<br/><br/>Our lab at the University of Chicago is located on the traditional homelands of the Ojibwe, Odawa, and Potawatomi nations.</p>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

            

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            The chatterlab is currently under construction so does not yet have a physical address or phone number.

            <a href="/contact/" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2022. Marisa Casillas. chatter lab.</p>
            
            <p class="pull-right">
              Template by <a href="https://bootstrapious.com/p/universal-business-e-commerce-template">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>.
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>


<script src="/chatterlab/js/front.js"></script>


<script src="/chatterlab/js/owl.carousel.min.js"></script>



  </body>
</html>
